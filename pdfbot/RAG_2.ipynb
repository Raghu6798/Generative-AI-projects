{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from datasets import load_dataset\n",
    "import cassio\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "astra_db_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "astra_id = os.getenv(\"ASTRA_ID\")\n",
    "groq_api = os.getenv(\"GROQ_API\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfreader = PdfReader(r'C:\\Users\\Raghu\\Downloads\\Gen AI Projects\\pdfbot\\basic-laws-book-2016.pdf')\n",
    "\n",
    "from typing_extensions import Concatenate\n",
    "\n",
    "raw_text = ''\n",
    "for i,page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=\"AstraCS:qpHtvznmeuyqrZrqOXXbiaSn:8a758fd88cf7c4c9e332ddc9ae51e97449de4fba23d43fdc8b795eeca07781e3\",database_id=\"b3c61e69-216f-4f17-a126-f56fc9793b6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raghu\\AppData\\Local\\Temp\\ipykernel_20184\\3048509702.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"llama3.1\")\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model=\"gemma2-9b-it\",api_key=os.getenv(\"GROQ_API\"))\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding=embeddings,\n",
    "    table_name=\"qa_mini_proj\",\n",
    "    session=None,\n",
    "    keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=\"\\n\\n\",chunk_size = 900,chunk_overlap = 200,length_function = len)\n",
    "\n",
    "text_chunks = text_splitter.split_text(raw_text)\n",
    "type(text_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50 headlines.\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(text_chunks[:50])\n",
    "print(f\"Inserted %i headlines.\" % len(text_chunks[:50]))\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "(a) Provisions pertaining to the Review Board.—The pro -\n",
       "visions of this Act that pertain to the appointment and \n",
       "operation of the Review Board shall cease to be effective \n",
       "when the Review Board and the terms of its members \n",
       "have terminated pursuant to section 7(o).\n",
       "(b) Other provisions.—The remaining provisions of this \n",
       "Act shall continue in effect until such time as the Archivist \n",
       "certifies to the President and the Congress that all assassi -\n",
       "nation records have been made available to the public in \n",
       "accordance with this Act.\n",
       "Sec. 13. Authorization of appropriations\n",
       "(a) In general.—There are authorized to be appropriated \n",
       "to carry out the provisions of this Act $1,600,000 for fis -\n",
       "cal year 1998.\n",
       "(b) Interim funding.—Until such time as funds are ap -\n",
       "propriated pursuant to subsection (a), the President may \n",
       "use such sums as are available for discretionary use to car -\n",
       "ry out this Act."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(text_chunks[199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide the document so I can answer your question. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Define the prompt template\n",
    "query_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "Based on the document content, provide a detailed response to the following question.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Ensure the answer is based strictly on the available document text. If the requested information is not in the document, respond with \"This document does not contain the answer to this question.\"\n",
    "\n",
    "Response:\n",
    "\"\"\",\n",
    ")\n",
    "# Initialize the parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Example usage\n",
    "query_text = \"What is the authorization for appropriations in this Act?\"\n",
    "chain = query_prompt | llm | output_parser\n",
    "response = chain.invoke({\"query\":query_text})\n",
    "Markdown(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
