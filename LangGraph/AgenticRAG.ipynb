{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:kHbIygIgPtniwYIzRsZAAvUK:d5c77950270bf75d939b99184b79f9c59db80ffde982d24c75c4af336397a0a8\"\n",
    "ASTRA_DB_ID = \"c2d3c0e3-b214-4042-8337-7f53fa6777bb\"\n",
    "cassio.init(token = ASTRA_DB_APPLICATION_TOKEN,database_id = ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content='LangGraph Studio\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n              LangGraph Studio\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n  \\n    \\n  \\n  Home\\n\\n      \\n\\n\\n\\n          \\n  \\n    \\n  \\n  Tutorials\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  How-to Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  Conceptual Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Home\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Tutorials\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    How-to Guides\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Conceptual Guides\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n  \\n    Conceptual Guides\\n  \\n\\n          \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    LangGraph\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    LangGraph\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Why LangGraph?\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Glossary\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Agent architectures\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Multi-agent Systems\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Human-in-the-loop\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Persistence\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Memory\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Streaming\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    FAQ\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Platform\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    LangGraph Platform\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    LangGraph Platform\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    High Level'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content='Streaming\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    FAQ\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Platform\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    LangGraph Platform\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    LangGraph Platform\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    High Level\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Components\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    Components\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    Components\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Server\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Studio\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n    \\n  \\n    LangGraph Studio\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      \\n        Features\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Types\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Desktop app\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Cloud studio\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Development server\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Studio FAQs\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Why is my project failing to start?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Docker issues (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Configuration or environment issues\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        How does interrupt work?\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How do I reload the app? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How does automatic rebuilding work? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Rebuilds from source code changes\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Rebuilds from configuration or dependency changes\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why is my graph taking so long to startup? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why are extra edges showing up in my graph?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Solution 1: Include a path map'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content='Rebuilds from source code changes\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Rebuilds from configuration or dependency changes\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why is my graph taking so long to startup? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why are extra edges showing up in my graph?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Solution 1: Include a path map\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Solution 2: Update the typing of the router (Python only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Related\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph CLI\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph SDK\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    How to interact with the deployment using RemoteGraph\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Server\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Deployment Options\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Reference\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      \\n        Features\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Types\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Desktop app\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Cloud studio\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Development server\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Studio FAQs\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Why is my project failing to start?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Docker issues (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Configuration or environment issues\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        How does interrupt work?\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How do I reload the app? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How does automatic rebuilding work? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Rebuilds from source code changes\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Rebuilds from configuration or dependency changes'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content='How does interrupt work?\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How do I reload the app? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How does automatic rebuilding work? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Rebuilds from source code changes\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Rebuilds from configuration or dependency changes\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why is my graph taking so long to startup? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why are extra edges showing up in my graph?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Solution 1: Include a path map\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Solution 2: Update the typing of the router (Python only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Related\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Home\\n  \\n\\n\\n\\n\\n\\n    Conceptual Guides\\n  \\n\\n\\n\\n\\n\\n    LangGraph Platform\\n  \\n\\n\\n\\n\\n\\n    Components\\n  \\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio¶\\n\\nPrerequisites\\n\\nLangGraph Platform\\nLangGraph Server\\n\\n\\nLangGraph Studio offers a new way to develop LLM applications by providing a specialized agent IDE that enables visualization, interaction, and debugging of complex agentic applications.\\nWith visual graphs and the ability to edit state, you can better understand agent workflows and iterate faster. LangGraph Studio integrates with LangSmith allowing you to  collaborate with teammates to debug failure modes.\\n\\nFeatures¶\\nThe key features of LangGraph Studio are:\\n\\nVisualizes your graph\\nTest your graph by running it from the UI\\nDebug your agent by modifying its state and rerunning\\nCreate and manage assistants\\nView and manage threads\\nView and manage long term memory\\nAdd node input/outputs to LangSmith datasets for testing'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content=\"Types¶\\nDesktop app¶\\nLangGraph Studio is available as a desktop app for MacOS users.\\nWhile in Beta, LangGraph Studio is available for free to all LangSmith users on any plan tier.\\nCloud studio¶\\nIf you have deployed your LangGraph application on LangGraph Platform (Cloud), you can access the studio as part of that\\nDevelopment server¶\\nLangGraph CLI also contains a command for running an in-memory development server that can be used to connect a local LangGraph app with the studio.\\nSee instructions here for more information.\\nThe way this works is that it runs inside your local environment.\\nIt will spin up an in-memory, development server to deploy the graph.\\nYou can then connect to the studio via the Cloud hosted version of LangGraph Platform.\\nTo be clear, the web studio will connect to your locally running server - your agent is still running locally and never leaves your device.\\nStudio FAQs¶\\nWhy is my project failing to start?¶\\nThere are a few reasons that your project might fail to start, here are some of the most common ones.\\nDocker issues (desktop only)¶\\nLangGraph Studio (desktop) requires Docker Desktop version 4.24 or higher. Please make sure you have a version of Docker installed that satisfies that requirement and also make sure you have the Docker Desktop app up and running before trying to use LangGraph Studio. In addition, make sure you have docker-compose updated to version 2.22.0 or higher.\\nConfiguration or environment issues¶\\nAnother reason your project might fail to start is because your configuration file is defined incorrectly, or you are missing required environment variables. \\nHow does interrupt work?¶\\nWhen you select the Interrupts dropdown and select a node to interrupt the graph will pause execution before and after (unless the node goes straight to END) that node has run. This means that you will be able to both edit the state before the node is ran and the state after the node has ran. This is intended to allow developers more fine-grained control over the behavior of a node and make it easier to observe how the node is behaving. You will not be able to edit the state after the node has ran if the node is the final node in the graph.\\nHow do I reload the app?  (desktop only)¶\\nIf you would like to reload the app, don't use Command+R as you might normally do. Instead, close and reopen the app for a full refresh.\\nHow does automatic rebuilding work?  (desktop only)¶\\nOne of the key features of LangGraph Studio is that it automatically rebuilds your image when you change the source code. This allows for a super fast development and testing cycle which makes it easy to iterate on your graph. There are two different ways that LangGraph rebuilds your image: either by editing the image or completely rebuilding it.\\nRebuilds from source code changes¶\\nIf you modified the source code only (no configuration or dependency changes!) then the image does not require a full rebuild, and LangGraph Studio will only update the relevant parts. The UI status in the bottom left will switch from Online to Stopping temporarily while the image gets edited. The logs will be shown as this process is happening, and after the image has been edited the status will change back to Online and you will be able to run your graph with the modified code!\\nRebuilds from configuration or dependency changes¶\\nIf you edit your graph configuration file (langgraph.json) or the dependencies (either pyproject.toml or requirements.txt) then the entire image will be rebuilt. This will cause the UI to switch away from the graph view and start showing the logs of the new image building process. This can take a minute or two, and once it is done your updated image will be ready to use!\\nWhy is my graph taking so long to startup?  (desktop only)¶\\nThe LangGraph Studio interacts with a local LangGraph API server. To stay aligned with ongoing updates, the LangGraph API requires regular rebuilding. As a result, you may occasionally experience slight delays when starting up your project.\\nWhy are extra edges showing up in my graph?¶\\nIf you don't define your conditional edges carefully, you might notice extra edges appearing in your graph. This is because without proper definition, LangGraph Studio assumes the conditional edge could access all other nodes. In order for this to not be the case, you need to be explicit about how you define the nodes the conditional edge routes to. There are two ways you can do this:\\nSolution 1: Include a path map¶\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content=\"Why is my graph taking so long to startup?  (desktop only)¶\\nThe LangGraph Studio interacts with a local LangGraph API server. To stay aligned with ongoing updates, the LangGraph API requires regular rebuilding. As a result, you may occasionally experience slight delays when starting up your project.\\nWhy are extra edges showing up in my graph?¶\\nIf you don't define your conditional edges carefully, you might notice extra edges appearing in your graph. This is because without proper definition, LangGraph Studio assumes the conditional edge could access all other nodes. In order for this to not be the case, you need to be explicit about how you define the nodes the conditional edge routes to. There are two ways you can do this:\\nSolution 1: Include a path map¶\\nThe first way to solve this is to add path maps to your conditional edges. A path map is just a dictionary or array that maps the possible outputs of your router function with the names of the nodes that each output corresponds to. The path map is passed as the third argument to the add_conditional_edges function like so:\\nPythonJavascript\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content='graph.add_conditional_edges(\"node_a\", routing_function, {True: \"node_b\", False: \"node_c\"})\\n\\n\\n\\ngraph.addConditionalEdges(\"node_a\", routingFunction, { true: \"node_b\", false: \"node_c\" });\\n\\n\\n\\n\\nIn this case, the routing function returns either True or False, which map to node_b and node_c respectively.\\nSolution 2: Update the typing of the router (Python only)¶\\nInstead of passing a path map, you can also be explicit about the typing of your routing function by specifying the nodes it can map to using the Literal python definition. Here is an example of how to define a routing function in that way:\\ndef routing_function(state: GraphState) -> Literal[\"node_b\",\"node_c\"]:\\n    if state[\\'some_condition\\'] == True:\\n        return \"node_b\"\\n    else:\\n        return \"node_c\"\\n\\nRelated¶\\nFor more information please see the following:\\n\\nLangGraph Studio how-to guides\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                LangGraph Server\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                LangGraph CLI\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs Insiders'),\n",
       " Document(metadata={'source': 'https://inference-docs.cerebras.ai/quickstart', 'title': 'QuickStart - Cerebras Inference', 'language': 'en'}, page_content='QuickStart - Cerebras InferenceCerebras Inference home pageSearch or ask...Search...NavigationGet StartedQuickStartDocumentationAPI ReferenceCerebras Inference home pageAboutCommunityBlogPython SDKNode.js SDKGet StartedOverviewQuickStartCapabilitiesStreaming ResponsesTool UseResourcesIntegrationsExamplesOpenAI CompatibilityAI Agent BootcampIntroduction to AI AgentsTool Use and Function CallingSupportError CodesRelease NotesGet StartedQuickStartThis QuickStart guide is designed to assist you in making your first API call. If you are an experienced AI applications developer, you may find it more beneficial to go directly to the API reference documentation.\\nIf you would like to interact with the models using Cerebras’ Inference solution before making an API call, please visit the developer playground.\\nThis guide will walk you through:\\n\\nSetting up your developer environment\\nInstalling the Cerebras Inference library\\nMaking your first request to the Cerebras API\\n\\n\\u200bPrerequisites\\nTo complete this guide, you will need:\\n\\nA Cerebras account\\nA Cerebras Inference API key\\nPython 3.7+ or TypeScript 4.5+\\n\\n\\u200bStep 1: Set up your API key\\nThe first thing you will need is a valid API key. Please visit this link and navigate to “API Keys” on the left nav bar.\\nFor security reasons and to avoid configuring your API key each time, it is recommended to set your API key as an environment variable. You can do this by running the following command in your terminal:\\nexport CEREBRAS_API_KEY=\"your-api-key-here\"\\n\\n\\u200bStep 2: Install the Cerebras Inference library\\nThe Cerebras Inference library is available for download and installation through the Python Package Index (PyPI) and the npm package manager. To install the library run either of the following commands in your terminal, based on your language of choice:\\nNote: You can also call the underlying API directly (see cURL request example below in Step 3).\\n\\n\\u200bStep 3: Making an API request\\nIf your request is being blocked by CloudFront, ensure that User-Agent is included in your headers\\nOnce you have configured your API key, you are ready to send your first API request.\\nThe following code snippets demonstrate how to make an API request to the Cerebras API to perform a chat completion.\\n\\n\\u200bNext Steps\\n\\nVisit our repositories for our Python and Node.js libraries\\nCheck out our API Reference to learn about the details of our available endpoints and request parameters.\\nLearn how to stream responses.\\nLearn about tool use.\\nWas this page helpful?YesNoOverviewStreaming ResponsesPowered by MintlifyOn this pagePrerequisitesStep 1: Set up your API keyStep 2: Install the Cerebras Inference libraryStep 3: Making an API requestNext Steps'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': \"LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain's open source frameworks is not necessary - LangSmith works on its own!\", 'language': 'en'}, page_content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Cloud)AdministrationSelf-hostingReferenceQuick StartOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain\\'s open source frameworks is not necessary - LangSmith works on its own!\\n1. Install LangSmith‚Äã\\nPythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\\n2. Create an API key‚Äã\\nTo create an API key head to the Settings page. Then click Create API Key.\\n3. Set up your environment‚Äã\\nShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>\\n4. Log your first trace‚Äã\\nLangSmith + LangChain OSSYou don\\'t need to use the LangSmith SDK directly if your application is built on LangChain/LangGraph (either Python and JS).See the how-to guide for tracing with LangChain here.\\nWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\nhow to use traceable(). See more on the Annotate code for tracing page.\\nPythonTypeScriptimport openaifrom langsmith.wrappers import wrap_openaifrom langsmith import traceable# Auto-trace LLM calls in-contextclient = wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-4o-mini\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-4o-mini\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?\\n\\nView a sample output trace.\\nLearn more about tracing in the observability tutorials, conceptual guide and how-to guides.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': \"LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain's open source frameworks is not necessary - LangSmith works on its own!\", 'language': 'en'}, page_content='View a sample output trace.\\nLearn more about tracing in the observability tutorials, conceptual guide and how-to guides.\\n\\n5. Run your first evaluation‚Äã\\nEvaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.\\nPythonTypeScriptfrom langsmith import Client, evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(  inputs=[      {\"postfix\": \"to LangSmith\"},      {\"postfix\": \"to Evaluations in LangSmith\"},  ],  outputs=[      {\"output\": \"Welcome to LangSmith\"},      {\"output\": \"Welcome to Evaluations in LangSmith\"},  ],  dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):  return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(  lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here  data=dataset_name, # The data to predict and grade over  evaluators=[exact_match], # The evaluators to score the results  experiment_prefix=\"sample-experiment\", # The name of the experiment  metadata={    \"version\": \"1.0.0\",    \"revision_id\": \"beta\"  },)import { Client, Run, Example } from \"langsmith\";import { EvaluationResult, evaluate } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });\\n\\nClick the link printed out by your evaluation run to access the LangSmith experiments UI,\\nand explore the results of your evaluation.\\nLearn more about evaluation in the tutorials, conceptual guide, and how-to guides.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/\",\n",
    "    \"https://inference-docs.cerebras.ai/quickstart\",\n",
    "    \"https://docs.smith.langchain.com/\"\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "doc_list = [item for sublist in docs for item in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000,chunk_overlap = 200)\n",
    "texts = text_splitter.split_documents(doc_list)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Raghu\\OneDrive\\Documents\\Anaconda\\envs\\LSTM\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 10 headlines :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3b43e8aa9734457196f09ade4ec8a332',\n",
       " '0b214376475840de829bcb6a3b1e1608',\n",
       " 'c4ea9de519d74e4791cf4203eff0a408']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "\n",
    "astra_vector_store = Cassandra(embedding=embeddings,table_name = \"qa_mini_demo\",session=None,keyspace=None)\n",
    "\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "print(\"Inserted %i headlines :\" % len(texts))\n",
    "astra_vector_store.add_documents(doc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c4ea9de519d74e4791cf4203eff0a408', metadata={'description': \"LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain's open source frameworks is not necessary - LangSmith works on its own!\", 'language': 'en', 'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}, page_content='\\n\\n\\n\\n\\nGet started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Cloud)AdministrationSelf-hostingReferenceQuick StartOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain\\'s open source frameworks is not necessary - LangSmith works on its own!\\n1. Install LangSmith‚Äã\\nPythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\\n2. Create an API key‚Äã\\nTo create an API key head to the Settings page. Then click Create API Key.\\n3. Set up your environment‚Äã\\nShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>\\n4. Log your first trace‚Äã\\nLangSmith + LangChain OSSYou don\\'t need to use the LangSmith SDK directly if your application is built on LangChain/LangGraph (either Python and JS).See the how-to guide for tracing with LangChain here.\\nWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\nhow to use traceable(). See more on the Annotate code for tracing page.\\nPythonTypeScriptimport openaifrom langsmith.wrappers import wrap_openaifrom langsmith import traceable# Auto-trace LLM calls in-contextclient = wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-4o-mini\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-4o-mini\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?\\n\\nView a sample output trace.\\nLearn more about tracing in the observability tutorials, conceptual guide and how-to guides.\\n\\n5. Run your first evaluation‚Äã\\nEvaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.\\nPythonTypeScriptfrom langsmith import Client, evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(  inputs=[      {\"postfix\": \"to LangSmith\"},      {\"postfix\": \"to Evaluations in LangSmith\"},  ],  outputs=[      {\"output\": \"Welcome to LangSmith\"},      {\"output\": \"Welcome to Evaluations in LangSmith\"},  ],  dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):  return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(  lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here  data=dataset_name, # The data to predict and grade over  evaluators=[exact_match], # The evaluators to score the results  experiment_prefix=\"sample-experiment\", # The name of the experiment  metadata={    \"version\": \"1.0.0\",    \"revision_id\": \"beta\"  },)import { Client, Run, Example } from \"langsmith\";import { EvaluationResult, evaluate } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });\\n\\nClick the link printed out by your evaluation run to access the LangSmith experiments UI,\\nand explore the results of your evaluation.\\nLearn more about evaluation in the tutorials, conceptual guide, and how-to guides.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\\n\\n'),\n",
       " Document(id='0b214376475840de829bcb6a3b1e1608', metadata={'language': 'en', 'source': 'https://inference-docs.cerebras.ai/quickstart', 'title': 'QuickStart - Cerebras Inference'}, page_content='QuickStart - Cerebras InferenceCerebras Inference home pageSearch or ask...Search...NavigationGet StartedQuickStartDocumentationAPI ReferenceCerebras Inference home pageAboutCommunityBlogPython SDKNode.js SDKGet StartedOverviewQuickStartCapabilitiesStreaming ResponsesTool UseResourcesIntegrationsExamplesOpenAI CompatibilityAI Agent BootcampIntroduction to AI AgentsTool Use and Function CallingSupportError CodesRelease NotesGet StartedQuickStartThis QuickStart guide is designed to assist you in making your first API call. If you are an experienced AI applications developer, you may find it more beneficial to go directly to the API reference documentation.\\nIf you would like to interact with the models using Cerebras’ Inference solution before making an API call, please visit the developer playground.\\nThis guide will walk you through:\\n\\nSetting up your developer environment\\nInstalling the Cerebras Inference library\\nMaking your first request to the Cerebras API\\n\\n\\u200bPrerequisites\\nTo complete this guide, you will need:\\n\\nA Cerebras account\\nA Cerebras Inference API key\\nPython 3.7+ or TypeScript 4.5+\\n\\n\\u200bStep 1: Set up your API key\\nThe first thing you will need is a valid API key. Please visit this link and navigate to “API Keys” on the left nav bar.\\nFor security reasons and to avoid configuring your API key each time, it is recommended to set your API key as an environment variable. You can do this by running the following command in your terminal:\\nexport CEREBRAS_API_KEY=\"your-api-key-here\"\\n\\n\\u200bStep 2: Install the Cerebras Inference library\\nThe Cerebras Inference library is available for download and installation through the Python Package Index (PyPI) and the npm package manager. To install the library run either of the following commands in your terminal, based on your language of choice:\\nNote: You can also call the underlying API directly (see cURL request example below in Step 3).\\n\\n\\u200bStep 3: Making an API request\\nIf your request is being blocked by CloudFront, ensure that User-Agent is included in your headers\\nOnce you have configured your API key, you are ready to send your first API request.\\nThe following code snippets demonstrate how to make an API request to the Cerebras API to perform a chat completion.\\n\\n\\u200bNext Steps\\n\\nVisit our repositories for our Python and Node.js libraries\\nCheck out our API Reference to learn about the details of our available endpoints and request parameters.\\nLearn how to stream responses.\\nLearn about tool use.\\nWas this page helpful?YesNoOverviewStreaming ResponsesPowered by MintlifyOn this pagePrerequisitesStep 1: Set up your API keyStep 2: Install the Cerebras Inference libraryStep 3: Making an API requestNext Steps'),\n",
       " Document(id='3b43e8aa9734457196f09ade4ec8a332', metadata={'description': 'Build language agents as graphs', 'language': 'en', 'source': 'https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/', 'title': 'LangGraph Studio'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n              LangGraph Studio\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n  \\n    \\n  \\n  Home\\n\\n      \\n\\n\\n\\n          \\n  \\n    \\n  \\n  Tutorials\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  How-to Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  Conceptual Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Home\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Tutorials\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    How-to Guides\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Conceptual Guides\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n  \\n    Conceptual Guides\\n  \\n\\n          \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    LangGraph\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    LangGraph\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Why LangGraph?\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Glossary\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Agent architectures\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Multi-agent Systems\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Human-in-the-loop\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Persistence\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Memory\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Streaming\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    FAQ\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Platform\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    LangGraph Platform\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    LangGraph Platform\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    High Level\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Components\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    Components\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    Components\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Server\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Studio\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n    \\n  \\n    LangGraph Studio\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      \\n        Features\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Types\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Desktop app\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Cloud studio\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Development server\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Studio FAQs\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Why is my project failing to start?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Docker issues (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Configuration or environment issues\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        How does interrupt work?\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How do I reload the app? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How does automatic rebuilding work? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Rebuilds from source code changes\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Rebuilds from configuration or dependency changes\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why is my graph taking so long to startup? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why are extra edges showing up in my graph?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Solution 1: Include a path map\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Solution 2: Update the typing of the router (Python only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Related\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph CLI\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph SDK\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    How to interact with the deployment using RemoteGraph\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Server\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Deployment Options\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Reference\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      \\n        Features\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Types\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Desktop app\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Cloud studio\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Development server\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Studio FAQs\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Why is my project failing to start?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Docker issues (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Configuration or environment issues\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        How does interrupt work?\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How do I reload the app? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        How does automatic rebuilding work? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Rebuilds from source code changes\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Rebuilds from configuration or dependency changes\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why is my graph taking so long to startup? (desktop only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Why are extra edges showing up in my graph?\\n      \\n    \\n\\n\\n\\n\\n\\n\\n      \\n        Solution 1: Include a path map\\n      \\n    \\n\\n\\n\\n\\n\\n      \\n        Solution 2: Update the typing of the router (Python only)\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      \\n        Related\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Home\\n  \\n\\n\\n\\n\\n\\n    Conceptual Guides\\n  \\n\\n\\n\\n\\n\\n    LangGraph Platform\\n  \\n\\n\\n\\n\\n\\n    Components\\n  \\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio¶\\n\\nPrerequisites\\n\\nLangGraph Platform\\nLangGraph Server\\n\\n\\nLangGraph Studio offers a new way to develop LLM applications by providing a specialized agent IDE that enables visualization, interaction, and debugging of complex agentic applications.\\nWith visual graphs and the ability to edit state, you can better understand agent workflows and iterate faster. LangGraph Studio integrates with LangSmith allowing you to  collaborate with teammates to debug failure modes.\\n\\nFeatures¶\\nThe key features of LangGraph Studio are:\\n\\nVisualizes your graph\\nTest your graph by running it from the UI\\nDebug your agent by modifying its state and rerunning\\nCreate and manage assistants\\nView and manage threads\\nView and manage long term memory\\nAdd node input/outputs to LangSmith datasets for testing\\n\\nTypes¶\\nDesktop app¶\\nLangGraph Studio is available as a desktop app for MacOS users.\\nWhile in Beta, LangGraph Studio is available for free to all LangSmith users on any plan tier.\\nCloud studio¶\\nIf you have deployed your LangGraph application on LangGraph Platform (Cloud), you can access the studio as part of that\\nDevelopment server¶\\nLangGraph CLI also contains a command for running an in-memory development server that can be used to connect a local LangGraph app with the studio.\\nSee instructions here for more information.\\nThe way this works is that it runs inside your local environment.\\nIt will spin up an in-memory, development server to deploy the graph.\\nYou can then connect to the studio via the Cloud hosted version of LangGraph Platform.\\nTo be clear, the web studio will connect to your locally running server - your agent is still running locally and never leaves your device.\\nStudio FAQs¶\\nWhy is my project failing to start?¶\\nThere are a few reasons that your project might fail to start, here are some of the most common ones.\\nDocker issues (desktop only)¶\\nLangGraph Studio (desktop) requires Docker Desktop version 4.24 or higher. Please make sure you have a version of Docker installed that satisfies that requirement and also make sure you have the Docker Desktop app up and running before trying to use LangGraph Studio. In addition, make sure you have docker-compose updated to version 2.22.0 or higher.\\nConfiguration or environment issues¶\\nAnother reason your project might fail to start is because your configuration file is defined incorrectly, or you are missing required environment variables. \\nHow does interrupt work?¶\\nWhen you select the Interrupts dropdown and select a node to interrupt the graph will pause execution before and after (unless the node goes straight to END) that node has run. This means that you will be able to both edit the state before the node is ran and the state after the node has ran. This is intended to allow developers more fine-grained control over the behavior of a node and make it easier to observe how the node is behaving. You will not be able to edit the state after the node has ran if the node is the final node in the graph.\\nHow do I reload the app?  (desktop only)¶\\nIf you would like to reload the app, don\\'t use Command+R as you might normally do. Instead, close and reopen the app for a full refresh.\\nHow does automatic rebuilding work?  (desktop only)¶\\nOne of the key features of LangGraph Studio is that it automatically rebuilds your image when you change the source code. This allows for a super fast development and testing cycle which makes it easy to iterate on your graph. There are two different ways that LangGraph rebuilds your image: either by editing the image or completely rebuilding it.\\nRebuilds from source code changes¶\\nIf you modified the source code only (no configuration or dependency changes!) then the image does not require a full rebuild, and LangGraph Studio will only update the relevant parts. The UI status in the bottom left will switch from Online to Stopping temporarily while the image gets edited. The logs will be shown as this process is happening, and after the image has been edited the status will change back to Online and you will be able to run your graph with the modified code!\\nRebuilds from configuration or dependency changes¶\\nIf you edit your graph configuration file (langgraph.json) or the dependencies (either pyproject.toml or requirements.txt) then the entire image will be rebuilt. This will cause the UI to switch away from the graph view and start showing the logs of the new image building process. This can take a minute or two, and once it is done your updated image will be ready to use!\\nWhy is my graph taking so long to startup?  (desktop only)¶\\nThe LangGraph Studio interacts with a local LangGraph API server. To stay aligned with ongoing updates, the LangGraph API requires regular rebuilding. As a result, you may occasionally experience slight delays when starting up your project.\\nWhy are extra edges showing up in my graph?¶\\nIf you don\\'t define your conditional edges carefully, you might notice extra edges appearing in your graph. This is because without proper definition, LangGraph Studio assumes the conditional edge could access all other nodes. In order for this to not be the case, you need to be explicit about how you define the nodes the conditional edge routes to. There are two ways you can do this:\\nSolution 1: Include a path map¶\\nThe first way to solve this is to add path maps to your conditional edges. A path map is just a dictionary or array that maps the possible outputs of your router function with the names of the nodes that each output corresponds to. The path map is passed as the third argument to the add_conditional_edges function like so:\\nPythonJavascript\\n\\n\\ngraph.add_conditional_edges(\"node_a\", routing_function, {True: \"node_b\", False: \"node_c\"})\\n\\n\\n\\ngraph.addConditionalEdges(\"node_a\", routingFunction, { true: \"node_b\", false: \"node_c\" });\\n\\n\\n\\n\\nIn this case, the routing function returns either True or False, which map to node_b and node_c respectively.\\nSolution 2: Update the typing of the router (Python only)¶\\nInstead of passing a path map, you can also be explicit about the typing of your routing function by specifying the nodes it can map to using the Literal python definition. Here is an example of how to define a routing function in that way:\\ndef routing_function(state: GraphState) -> Literal[\"node_b\",\"node_c\"]:\\n    if state[\\'some_condition\\'] == True:\\n        return \"node_b\"\\n    else:\\n        return \"node_c\"\\n\\nRelated¶\\nFor more information please see the following:\\n\\nLangGraph Studio how-to guides\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                LangGraph Server\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                LangGraph CLI\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs Insiders\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "retriever = astra_vector_store.as_retriever()\n",
    "response = retriever.invoke(\"What is an agent?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\",\"wiki_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to wikipedia or vectorstore.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\") \n",
    "llm = ChatGroq(model_name = \"llama3-groq-70b-8192-tool-use-preview\",api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_router = llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or wikipedia.The vectorstore contains documents related to langgraph,cerebras and langsmith.Use the vectorstore for questions on these topics.Otherwise , use wiki search\n",
    "\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system),\n",
    "        (\"human\",\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = question_router.invoke(\n",
    "    {\n",
    "        \"question\" : \"What is langgraph?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(datasource='vectorstore')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(datasource='wiki_search')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2 = question_router.invoke(\n",
    "    {\n",
    "        \"question\":\"Who is gautam adani\"\n",
    "    }\n",
    ")\n",
    "response_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing wikipedia tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import  WikipediaQueryRun\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now the agentic workflow using langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\" \n",
    "    Represents the state of our graph\n",
    "\n",
    "    Attributes:\n",
    "    question:question\n",
    "    generation: LLM Generation\n",
    "    documents:list of documents\n",
    "    \"\"\"\n",
    "    question:str\n",
    "    generation:str\n",
    "    documents:List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\" \n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "      state (dict): The state of the task.\n",
    "    Returns:\n",
    "      state(dict): new key added to state,documents,that contains retrieved documents\n",
    "      \"\"\"\n",
    "    print(\"----Retrieve----\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents,\"question\":question}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def wiki_search(state):\n",
    "    \"\"\" \n",
    "    wiki search based on the re-phrased question\n",
    "\n",
    "    Args:\n",
    "      state (dict): The state of the task.\n",
    "    Returns:\n",
    "      state(dict): Updated documents key with appended web results\n",
    "      \"\"\"\n",
    "    \n",
    "    print(\"----wikipedia----\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    docs = wiki_tool.invoke({\"query\":question})\n",
    "    wiki_results = docs\n",
    "    wiki_results = Document(page_content=wiki_results)\n",
    "\n",
    "    return {\"documents\":wiki_results,\"question\":question}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\" \n",
    "    Route question to wiki search or RAG\n",
    "\n",
    "    Args:\n",
    "    state(dict): The current graph state \n",
    "\n",
    "    Returns:\n",
    "    str:Next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\":question})\n",
    "    if source.datasource == \"wiki_search\":\n",
    "        print(\"---ROUTE QUESTION TO WIKI SEARCH---\")\n",
    "        return \"wiki_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END,StateGraph,START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"wiki_search\",wiki_search)\n",
    "workflow.add_node(\"retrieve\",retrieve)\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"wiki_search\":\"wiki_search\",\n",
    "        \"vectorstore\":\"retrieve\"\n",
    "        }\n",
    ")\n",
    "workflow.add_edge(\"retrieve\",END)\n",
    "workflow.add_edge(\"wiki_search\",END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image,display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"The exception raised is \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WIKI SEARCH---\n",
      "----wikipedia----\n",
      "who is saurav gangully?\n",
      "{'wiki_search': {'documents': Document(metadata={}, page_content='Page: Sourav Ganguly\\nSummary: Sourav Chandidas Ganguly ( ; natively spelled as Gangopadhyay; born 8 July 1972), also known as Dada (meaning \"elder brother\" in Bengali), is an Indian cricket commentato'),\n",
      "                 'question': 'who is saurav gangully?'}}\n",
      "\"Node 'wiki_search':\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Document' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     11\u001b[0m     pprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m value \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m         document \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m         pprint(document\u001b[38;5;241m.\u001b[39mdict()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo description available\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Document' has no len()"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"question\": \"who is saurav gangully?\"\n",
    "}\n",
    "\n",
    "# Stream the output and print the full response\n",
    "for output in app.stream(inputs):\n",
    "    pprint(output)  # Print the entire response for debugging\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        if 'documents' in value and len(value['documents']) > 0:\n",
    "            document = value['documents'][0]\n",
    "            pprint(document.dict().get('metadata', {}).get('description', 'No description available'))\n",
    "    pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
